{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979ada9f",
   "metadata": {},
   "source": [
    " # ğŸ§ª Automated Experiments Runner\n",
    " ×¡×§×¨×™×¤×˜ ×–×” ××¨×™×¥ ×¡×“×¨×ª × ×™×¡×•×™×™× ×œ×”×©×•×•××ª ××•×“×œ×™×.\n",
    " ×”×•× ×›×•×œ×œ:\n",
    " 1. ×˜×¢×™× ×ª ×“××˜×” ×•×¡×™× ×•×Ÿ ×ª×ª-×§×‘×•×¦×”.\n",
    " 2. ×”×’×“×¨×ª ××•×“×œ ×“×™× ××™ (ResNet18/50).\n",
    " 3. ×¤×•× ×§×¦×™×•×ª Loss ××ª×§×“××•×ª (BCE, Cosine).\n",
    " 4. ×©××™×¨×ª ×”××•×“×œ ×”×× ×¦×— ××›×œ × ×™×¡×•×™.\n",
    " 5. ×™×¦×™×¨×ª ×˜×‘×œ×ª ×¡×™×›×•× ×‘××§×¡×œ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b2dd82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# --- ×”×’×“×¨×•×ª ×’×œ×•×‘×œ×™×•×ª ---\n",
    "DATA_DIR = Path(\"DATA\")\n",
    "MODELS_DIR = Path(\"experiments_models\")\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SUBSET_SIZE = 1500  # ×›××•×ª ×”×ª××•× ×•×ª ×œ× ×™×¡×•×™ (×›-20% ××”×“××˜×”)\n",
    "NUM_EPOCHS = 5      # ××¡×¤×¨ ××¤×•×§×™× ×œ×›×œ × ×™×¡×•×™ (××¡×¤×™×§ ×›×“×™ ×œ×¨××•×ª ××’××”)\n",
    "\n",
    "print(f\"Running on: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2900c",
   "metadata": {},
   "source": [
    "# ## 1. Dataset Class\n",
    "# ×˜×¢×™× ×ª ×”×ª××•× ×•×ª, ×”××¡×™×›×•×ª ×•×”×•×•×§×˜×•×¨×™×."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c699448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotentialFlowDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', target_size=(512, 256)):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.split = split\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        self.img_dir = self.root_dir / \"images\" / split\n",
    "        self.mask_dir = self.root_dir / \"masks\" / split\n",
    "        self.flow_dir = self.root_dir / \"flow\" / split\n",
    "        \n",
    "        self.images = sorted(list(self.img_dir.glob(\"*.jpg\")))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        stem = img_path.stem\n",
    "        \n",
    "        # Load\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(str(self.mask_dir / f\"{stem}.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "        flow = np.load(str(self.flow_dir / f\"{stem}.npy\"))\n",
    "\n",
    "        # Resize\n",
    "        img = cv2.resize(img, self.target_size)\n",
    "        mask = cv2.resize(mask, self.target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        flow = cv2.resize(flow, self.target_size)\n",
    "\n",
    "        # To Tensor\n",
    "        img_tensor = torch.from_numpy(img).float() / 255.0\n",
    "        img_tensor = img_tensor.permute(2, 0, 1)\n",
    "        \n",
    "        mask_tensor = torch.from_numpy(mask).float() / 255.0\n",
    "        mask_tensor = mask_tensor.unsqueeze(0)\n",
    "        \n",
    "        flow_tensor = torch.from_numpy(flow).float()\n",
    "        flow_tensor = flow_tensor.permute(2, 0, 1)\n",
    "\n",
    "        return img_tensor, mask_tensor, flow_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1967a5",
   "metadata": {},
   "source": [
    "#  2. Dynamic Model Architecture\n",
    " ××•×“×œ ×©×™×•×“×¢ ×œ×”×—×œ×™×£ ××ª ×”-Encoder ×©×œ×• (ResNet18 ××• ResNet50) ×œ×¤×™ ×‘×§×©×”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c73bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicDualHeadModel(nn.Module):\n",
    "    def __init__(self, backbone_name='resnet18'):\n",
    "        super().__init__()\n",
    "        if backbone_name == 'resnet18':\n",
    "            base = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "            self.dims = [64, 64, 128, 256, 512]\n",
    "        elif backbone_name == 'resnet50':\n",
    "            base = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "            self.dims = [64, 256, 512, 1024, 2048]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown backbone: {backbone_name}\")\n",
    "            \n",
    "        layers = list(base.children())\n",
    "        self.layer0 = nn.Sequential(*layers[:3])\n",
    "        self.layer1 = nn.Sequential(*layers[3:5])\n",
    "        self.layer2 = layers[5]\n",
    "        self.layer3 = layers[6]\n",
    "        self.layer4 = layers[7]\n",
    "        \n",
    "        # Decoder ××•×ª×× ×“×™× ××™×ª ×œ×’×•×“×œ ×”×¢×¨×•×¦×™×\n",
    "        self.up4 = self._up_block(self.dims[4], self.dims[3])\n",
    "        self.up3 = self._up_block(self.dims[3]*2, self.dims[2])\n",
    "        self.up2 = self._up_block(self.dims[2]*2, self.dims[1])\n",
    "        self.up1 = self._up_block(self.dims[1]*2, 64)\n",
    "        self.up0 = self._up_block(128, 32)\n",
    "        \n",
    "        # Heads\n",
    "        self.potential_head = nn.Sequential(nn.Conv2d(32, 1, 1), nn.Sigmoid())\n",
    "        self.flow_head = nn.Sequential(nn.Conv2d(32, 2, 1), nn.Tanh())\n",
    "\n",
    "    def _up_block(self, in_c, out_c):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_c, out_c, 2, 2),\n",
    "            nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c), nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.layer0(x)\n",
    "        x1 = self.layer1(x0)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x4 = self.layer4(x3)\n",
    "        \n",
    "        up4 = self.up4(x4)\n",
    "        up3 = self.up3(torch.cat([up4, x3], 1))\n",
    "        up2 = self.up2(torch.cat([up3, x2], 1))\n",
    "        up1 = self.up1(torch.cat([up2, x1], 1))\n",
    "        feat = self.up0(torch.cat([up1, x0], 1))\n",
    "        \n",
    "        return self.potential_head(feat), self.flow_head(feat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ad0800",
   "metadata": {},
   "source": [
    "#  3. Losses & Metrics\n",
    " ×”×’×“×¨×ª ×¤×•× ×§×¦×™×•×ª ×”×¤×¡×“ (Cosine Similarity) ×•××“×“×™ ×‘×™×¦×•×¢×™× (IoU, Precision, Recall, EPE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d11b3722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineFlowLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.cosine = nn.CosineSimilarity(dim=1)\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        # ×©×™×œ×•×‘ ×©×œ ×“×™×•×§ ×‘×’×•×“×œ (MSE) ×•×“×™×•×§ ×‘×–×•×•×™×ª (Cosine)\n",
    "        return 0.7 * self.mse(pred, target) + 0.3 * (1 - self.cosine(pred, target).mean())\n",
    "\n",
    "def calculate_metrics(pred_pot, target_pot, pred_flow, target_flow):\n",
    "    # --- Segmentation Metrics (Potential) ---\n",
    "    pred_bin = (pred_pot > 0.5).float()\n",
    "    target_bin = (target_pot > 0.5).float()\n",
    "    \n",
    "    tp = (pred_bin * target_bin).sum().item()\n",
    "    fp = (pred_bin * (1-target_bin)).sum().item()\n",
    "    fn = ((1-pred_bin) * target_bin).sum().item()\n",
    "    \n",
    "    epsilon = 1e-6\n",
    "    iou = tp / (tp + fp + fn + epsilon)\n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "    \n",
    "    # --- Flow Metrics ---\n",
    "    # EPE: End Point Error (××¨×—×§ ××•×§×œ×™×“×™ ×××•×¦×¢ ×‘×™×Ÿ ×”×•×§×˜×•×¨×™×)\n",
    "    diff = pred_flow - target_flow\n",
    "    epe = torch.norm(diff, dim=1).mean().item()\n",
    "    \n",
    "    return iou, precision, recall, epe\n",
    "\n",
    "def measure_fps(model):\n",
    "    \"\"\"××“×™×“×ª ××”×™×¨×•×ª ×—×™×–×•×™ (×¤×¨×™×™××™× ×œ×©× ×™×™×”)\"\"\"\n",
    "    model.eval()\n",
    "    dummy = torch.randn(1, 3, 256, 512).to(DEVICE)\n",
    "    # ×—×™××•×\n",
    "    for _ in range(10): \n",
    "        with torch.no_grad(): model(dummy)\n",
    "        \n",
    "    start = time.time()\n",
    "    steps = 50\n",
    "    for _ in range(steps): \n",
    "        with torch.no_grad(): model(dummy)\n",
    "    return steps / (time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a101958",
   "metadata": {},
   "source": [
    "#  4. The Experiment Engine\n",
    " ×”×¤×•× ×§×¦×™×” ×©××¨×™×¦×” × ×™×¡×•×™ ×‘×•×“×“, ×©×•××¨×ª ××ª ×”××•×“×œ ×•××—×–×™×¨×” ×“×•×—.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c6a7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(config):\n",
    "    exp_name = config['name']\n",
    "    print(f\"\\nğŸ”¥ Experiment: {exp_name}\")\n",
    "    print(f\"   Config: Backbone={config['backbone']} | PotLoss={config['pot_loss']} | FlowLoss={config['flow_loss']} | Batch={config['batch']}\")\n",
    "    \n",
    "    # 1. ×”×›× ×ª ×”×“××˜×” (Subset ×œ×˜×•×‘×ª ××”×™×¨×•×ª)\n",
    "    full_ds = PotentialFlowDataset(DATA_DIR, 'train')\n",
    "    # ×‘×—×™×¨×” ××§×¨××™×ª ×©×œ ×ª××•× ×•×ª ×œ× ×™×¡×•×™\n",
    "    indices = np.random.choice(len(full_ds), min(SUBSET_SIZE, len(full_ds)), replace=False)\n",
    "    train_loader = DataLoader(Subset(full_ds, indices), batch_size=config['batch'], shuffle=True)\n",
    "    \n",
    "    # ×©×™××•×© ×‘-Val ×”××œ× ×œ×“×™×•×§\n",
    "    val_loader = DataLoader(PotentialFlowDataset(DATA_DIR, 'val'), batch_size=config['batch'])\n",
    "    \n",
    "    # 2. ×”×›× ×ª ×”××•×“×œ ×•×”××•×¤×˜×™××™×™×–×¨\n",
    "    model = DynamicDualHeadModel(config['backbone']).to(DEVICE)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    # 3. ×‘×—×™×¨×ª ×¤×•× ×§×¦×™×•×ª ×”×¤×¡×“\n",
    "    crit_pot = nn.BCELoss() if config['pot_loss'] == 'bce' else nn.MSELoss()\n",
    "    crit_flow = CosineFlowLoss() if config['flow_loss'] == 'cosine' else nn.MSELoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_metrics = np.zeros(4) # iou, prec, rec, epe\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 4. ×œ×•×œ××ª ××™××•×Ÿ\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Train\n",
    "        model.train()\n",
    "        for imgs, masks, flows in train_loader:\n",
    "            imgs, masks, flows = imgs.to(DEVICE), masks.to(DEVICE), flows.to(DEVICE)\n",
    "            pot_out, flow_out = model(imgs)\n",
    "            loss = crit_pot(pot_out, masks) + crit_flow(flow_out, flows)\n",
    "            \n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            \n",
    "        # Val & Metrics\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        metrics_sum = np.zeros(4)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, masks, flows in val_loader:\n",
    "                imgs, masks, flows = imgs.to(DEVICE), masks.to(DEVICE), flows.to(DEVICE)\n",
    "                pot_out, flow_out = model(imgs)\n",
    "                \n",
    "                val_loss += (crit_pot(pot_out, masks) + crit_flow(flow_out, flows)).item()\n",
    "                metrics_sum += calculate_metrics(pot_out, masks, flow_out, flows)\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        metrics_avg = metrics_sum / len(val_loader)\n",
    "        \n",
    "        print(f\"   Ep {epoch+1}: Val Loss={val_loss:.4f} | IoU={metrics_avg[0]:.3f} | EPE={metrics_avg[3]:.3f}\")\n",
    "        \n",
    "        # ×©××™×¨×ª ×”××•×“×œ ×”×˜×•×‘ ×‘×™×•×ª×¨ ×‘× ×™×¡×•×™ ×”× ×•×›×—×™\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_metrics = metrics_avg\n",
    "            # ×©××™×¨×” ×¢× ×©× ×™×™×—×•×“×™ ×œ× ×™×¡×•×™\n",
    "            torch.save(model.state_dict(), MODELS_DIR / f\"{exp_name}_best.pth\")\n",
    "            \n",
    "    # ××“×™×“×ª FPS ×‘×¡×•×£\n",
    "    fps = measure_fps(model)\n",
    "    total_time = (time.time() - start_time) / 60\n",
    "    \n",
    "    return {\n",
    "        \"Name\": exp_name,\n",
    "        \"Backbone\": config['backbone'],\n",
    "        \"Pot Loss\": config['pot_loss'],\n",
    "        \"Flow Loss\": config['flow_loss'],\n",
    "        \"Best Val Loss\": round(best_val_loss, 4),\n",
    "        \"IoU\": round(best_metrics[0], 3),\n",
    "        \"Precision\": round(best_metrics[1], 3),\n",
    "        \"Recall\": round(best_metrics[2], 3),\n",
    "        \"EPE (Flow Error)\": round(best_metrics[3], 3),\n",
    "        \"FPS\": round(fps, 1),\n",
    "        \"Time (min)\": round(total_time, 1)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87641db7",
   "metadata": {},
   "source": [
    "#  5. Execution\n",
    " ×”×’×“×¨×ª ×¨×©×™××ª ×”× ×™×¡×•×™×™× ×•×”×¨×¦×”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b353c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting 4 Experiments ---\n",
      "\n",
      "\n",
      "ğŸ”¥ Experiment: base_R18_MSE\n",
      "   Config: Backbone=resnet18 | PotLoss=mse | FlowLoss=mse | Batch=8\n",
      "   Ep 1: Val Loss=0.1432 | IoU=0.486 | EPE=0.246\n",
      "   Ep 2: Val Loss=0.0943 | IoU=0.673 | EPE=0.187\n",
      "   Ep 3: Val Loss=0.0682 | IoU=0.741 | EPE=0.156\n",
      "   Ep 4: Val Loss=0.0594 | IoU=0.755 | EPE=0.142\n",
      "   Ep 5: Val Loss=0.0518 | IoU=0.747 | EPE=0.132\n",
      "âœ… Finished base_R18_MSE\n",
      "\n",
      "\n",
      "ğŸ”¥ Experiment: base_R18_BCE\n",
      "   Config: Backbone=resnet18 | PotLoss=bce | FlowLoss=mse | Batch=8\n",
      "   Ep 1: Val Loss=0.3875 | IoU=0.601 | EPE=0.224\n",
      "   Ep 2: Val Loss=0.3176 | IoU=0.752 | EPE=0.161\n",
      "   Ep 3: Val Loss=0.2912 | IoU=0.740 | EPE=0.147\n",
      "   Ep 4: Val Loss=0.2685 | IoU=0.795 | EPE=0.134\n",
      "   Ep 5: Val Loss=0.2511 | IoU=0.797 | EPE=0.131\n",
      "âœ… Finished base_R18_BCE\n",
      "\n",
      "\n",
      "ğŸ”¥ Experiment: base_R18_FullLoss\n",
      "   Config: Backbone=resnet18 | PotLoss=bce | FlowLoss=cosine | Batch=8\n",
      "   Ep 1: Val Loss=0.6637 | IoU=0.622 | EPE=0.227\n",
      "   Ep 2: Val Loss=0.5839 | IoU=0.630 | EPE=0.178\n",
      "   Ep 3: Val Loss=0.5424 | IoU=0.669 | EPE=0.163\n",
      "   Ep 4: Val Loss=0.5095 | IoU=0.750 | EPE=0.151\n",
      "   Ep 5: Val Loss=0.4892 | IoU=0.737 | EPE=0.140\n",
      "âœ… Finished base_R18_FullLoss\n",
      "\n",
      "\n",
      "ğŸ”¥ Experiment: heavy_R50_FullLoss\n",
      "   Config: Backbone=resnet50 | PotLoss=bce | FlowLoss=cosine | Batch=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\guyy6/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:01<00:00, 62.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ep 1: Val Loss=0.6164 | IoU=0.623 | EPE=0.192\n",
      "   Ep 2: Val Loss=0.5248 | IoU=0.665 | EPE=0.161\n",
      "   Ep 3: Val Loss=0.4738 | IoU=0.782 | EPE=0.142\n",
      "   Ep 4: Val Loss=0.4494 | IoU=0.778 | EPE=0.126\n",
      "   Ep 5: Val Loss=0.4307 | IoU=0.801 | EPE=0.120\n",
      "âœ… Finished heavy_R50_FullLoss\n",
      "\n",
      "\n",
      "ğŸ† ALL EXPERIMENTS COMPLETED!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Backbone</th>\n",
       "      <th>Pot Loss</th>\n",
       "      <th>Flow Loss</th>\n",
       "      <th>Best Val Loss</th>\n",
       "      <th>IoU</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>EPE (Flow Error)</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Time (min)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base_R18_MSE</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>mse</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.132</td>\n",
       "      <td>289.2</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base_R18_BCE</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>bce</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.2511</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.131</td>\n",
       "      <td>308.5</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base_R18_FullLoss</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>bce</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.4892</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.140</td>\n",
       "      <td>188.8</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heavy_R50_FullLoss</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>bce</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.4307</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.120</td>\n",
       "      <td>90.6</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name  Backbone Pot Loss Flow Loss  Best Val Loss    IoU  \\\n",
       "0        base_R18_MSE  resnet18      mse       mse         0.0518  0.747   \n",
       "1        base_R18_BCE  resnet18      bce       mse         0.2511  0.797   \n",
       "2   base_R18_FullLoss  resnet18      bce    cosine         0.4892  0.737   \n",
       "3  heavy_R50_FullLoss  resnet50      bce    cosine         0.4307  0.801   \n",
       "\n",
       "   Precision  Recall  EPE (Flow Error)    FPS  Time (min)  \n",
       "0      0.788   0.936             0.132  289.2        12.2  \n",
       "1      0.863   0.910             0.131  308.5        12.4  \n",
       "2      0.759   0.961             0.140  188.8        11.6  \n",
       "3      0.877   0.901             0.120   90.6        13.8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiments_list = [\n",
    "    # 1. Base: ×”××¦×‘ ×”× ×•×›×—×™ (ResNet18 + MSE)\n",
    "    {\"name\": \"base_R18_MSE\", \"backbone\": \"resnet18\", \"pot_loss\": \"mse\", \"flow_loss\": \"mse\", \"batch\": 8},\n",
    "    \n",
    "    # 2. Loss A: ×©×™×¤×•×¨ ×¡×’×× ×˜×¦×™×” ×¢× BCE\n",
    "    {\"name\": \"base_R18_BCE\", \"backbone\": \"resnet18\", \"pot_loss\": \"bce\", \"flow_loss\": \"mse\", \"batch\": 8},\n",
    "    \n",
    "    # 3. Loss B: ×©×™×¤×•×¨ ××œ× (BCE ×œ××¤×” + Cosine ×œ×•×•×§×˜×•×¨×™×)\n",
    "    {\"name\": \"base_R18_FullLoss\", \"backbone\": \"resnet18\", \"pot_loss\": \"bce\", \"flow_loss\": \"cosine\", \"batch\": 8},\n",
    "    \n",
    "    # 4. Heavy: ××•×— ×—×–×§ ×™×•×ª×¨ (ResNet50) ×¢× ×”×œ×•×¡×™× ×”×—×“×©×™×\n",
    "    # ×©×™× ×œ×‘: ×”×•×¨×“× ×• Batch Size ×œ-4 ×›×™ ×”××•×“×œ ×›×‘×“ ×™×•×ª×¨\n",
    "    {\"name\": \"heavy_R50_FullLoss\", \"backbone\": \"resnet50\", \"pot_loss\": \"bce\", \"flow_loss\": \"cosine\", \"batch\": 4},\n",
    "]\n",
    "\n",
    "# ×”×¨×¦×ª ×”× ×™×¡×•×™×™×\n",
    "all_results = []\n",
    "print(f\"--- Starting {len(experiments_list)} Experiments ---\\n\")\n",
    "\n",
    "for exp_config in experiments_list:\n",
    "    try:\n",
    "        # ×”×¨×¦×ª ×”× ×™×¡×•×™ ×”×‘×•×“×“\n",
    "        res = run_experiment(exp_config)\n",
    "        all_results.append(res)\n",
    "        \n",
    "        # ×©××™×¨×ª ×‘×™× ×™×™× (×›×“×™ ×œ× ×œ××‘×“ × ×ª×•× ×™× ×× ×”××—×©×‘ ×§×•×¨×¡)\n",
    "        pd.DataFrame(all_results).to_csv(\"experiments_results.csv\", index=False)\n",
    "        print(f\"âœ… Finished {exp_config['name']}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed {exp_config['name']}: {e}\\n\")\n",
    "        torch.cuda.empty_cache() # × ×™×§×•×™ ×–×™×›×¨×•×Ÿ ×œ××§×¨×” ×©×œ × ×¤×™×œ×”\n",
    "\n",
    "# ×¡×™×›×•× ×¡×•×¤×™\n",
    "print(\"\\nğŸ† ALL EXPERIMENTS COMPLETED!\")\n",
    "final_df = pd.DataFrame(all_results)\n",
    "final_df.to_csv(\"experiments_results_final.csv\", index=False)\n",
    "\n",
    "# ×”×¦×’×ª ×”×˜×‘×œ×” ×‘×¤×•×¨××˜ ×§×¨×™× (×× ××¨×™×¦×™× ×‘-Notebook/Interactive)\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(final_df)\n",
    "except:\n",
    "    print(final_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9b9499",
   "metadata": {},
   "source": [
    "# ğŸ§ª Round 2: Advanced Loss & ResNet50 Focus\n",
    " ×‘×¡×™×‘×•×‘ ×”×–×” ×× ×• ××ª××§×“×™× ×‘××•×“×œ ×”×× ×¦×— (ResNet50) ×•×× ×¡×™× ×œ×©×¤×¨ ××ª ×”-Flow ×©×œ×•.\n",
    " ×‘× ×•×¡×£, ×× ×• ×‘×•×“×§×™× ×¤×•× ×§×¦×™×™×ª Loss ××©×•×œ×‘×ª (Combo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a7ed99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Round 2 (3 Experiments) ---\n",
      "\n",
      "\n",
      "ğŸ”¥ Round 2 Experiment: R50_BCE_MSE\n",
      "   Config: resnet50 | FlowLoss: mse\n",
      "   Ep 1: Val Loss=0.4893 | EPE=0.212\n",
      "   Ep 2: Val Loss=0.3737 | EPE=0.163\n",
      "   Ep 3: Val Loss=0.3122 | EPE=0.133\n",
      "   Ep 4: Val Loss=0.2715 | EPE=0.128\n",
      "   Ep 5: Val Loss=0.2506 | EPE=0.117\n",
      "âœ… Finished R50_BCE_MSE\n",
      "\n",
      "\n",
      "ğŸ”¥ Round 2 Experiment: R50_BCE_Combo\n",
      "   Config: resnet50 | FlowLoss: combo\n",
      "   Ep 1: Val Loss=0.8181 | EPE=0.261\n",
      "   Ep 2: Val Loss=0.7091 | EPE=0.174\n",
      "   Ep 3: Val Loss=0.6398 | EPE=0.153\n",
      "   Ep 4: Val Loss=0.6038 | EPE=0.143\n",
      "   Ep 5: Val Loss=0.5807 | EPE=0.137\n",
      "âœ… Finished R50_BCE_Combo\n",
      "\n",
      "\n",
      "ğŸ”¥ Round 2 Experiment: R18_BCE_Combo\n",
      "   Config: resnet18 | FlowLoss: combo\n",
      "   Ep 1: Val Loss=0.7859 | EPE=0.307\n",
      "   Ep 2: Val Loss=0.6904 | EPE=0.211\n",
      "   Ep 3: Val Loss=0.6479 | EPE=0.174\n",
      "   Ep 4: Val Loss=0.6251 | EPE=0.159\n",
      "   Ep 5: Val Loss=0.6051 | EPE=0.148\n",
      "âœ… Finished R18_BCE_Combo\n",
      "\n",
      "\n",
      "ğŸ† ROUND 2 COMPLETED!\n",
      "\n",
      "--- Combined Results (Top Models) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Backbone</th>\n",
       "      <th>Pot Loss</th>\n",
       "      <th>Flow Loss</th>\n",
       "      <th>Best Val Loss</th>\n",
       "      <th>IoU</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>EPE (Flow Error)</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Time (min)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R50_BCE_MSE</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117</td>\n",
       "      <td>88.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heavy_R50_FullLoss</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>bce</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.4307</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.120</td>\n",
       "      <td>90.6</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base_R18_BCE</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>bce</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.2511</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.131</td>\n",
       "      <td>308.5</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base_R18_MSE</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>mse</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.132</td>\n",
       "      <td>289.2</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R50_BCE_Combo</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>combo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137</td>\n",
       "      <td>95.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base_R18_FullLoss</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>bce</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.4892</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.140</td>\n",
       "      <td>188.8</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R18_BCE_Combo</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>combo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.148</td>\n",
       "      <td>197.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name  Backbone Pot Loss Flow Loss  Best Val Loss    IoU  \\\n",
       "4         R50_BCE_MSE  resnet50      NaN       mse            NaN  0.795   \n",
       "3  heavy_R50_FullLoss  resnet50      bce    cosine         0.4307  0.801   \n",
       "1        base_R18_BCE  resnet18      bce       mse         0.2511  0.797   \n",
       "0        base_R18_MSE  resnet18      mse       mse         0.0518  0.747   \n",
       "5       R50_BCE_Combo  resnet50      NaN     combo            NaN  0.779   \n",
       "2   base_R18_FullLoss  resnet18      bce    cosine         0.4892  0.737   \n",
       "6       R18_BCE_Combo  resnet18      NaN     combo            NaN  0.780   \n",
       "\n",
       "   Precision  Recall  EPE (Flow Error)    FPS  Time (min)  \n",
       "4        NaN     NaN             0.117   88.9         NaN  \n",
       "3      0.877   0.901             0.120   90.6        13.8  \n",
       "1      0.863   0.910             0.131  308.5        12.4  \n",
       "0      0.788   0.936             0.132  289.2        12.2  \n",
       "5        NaN     NaN             0.137   95.9         NaN  \n",
       "2      0.759   0.961             0.140  188.8        11.6  \n",
       "6        NaN     NaN             0.148  197.3         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ComboFlowLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.cosine = nn.CosineSimilarity(dim=1)\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        # MSE ×“×•××’ ×©×”×’×•×“×œ ×©×œ ×”×—×¥ ×™×”×™×” × ×›×•×Ÿ\n",
    "        loss_mse = self.mse(pred, target)\n",
    "        # Cosine ×“×•××’ ×©×”×–×•×•×™×ª ×ª×”×™×” ××“×•×™×§×ª\n",
    "        loss_cos = 1 - self.cosine(pred, target).mean()\n",
    "        \n",
    "        # ×©×™×œ×•×‘ ×××•×–×Ÿ: ×—×¦×™-×—×¦×™\n",
    "        return 0.5 * loss_mse + 0.5 * loss_cos\n",
    "\n",
    "# 2. ×¢×“×›×•×Ÿ ×¤×•× ×§×¦×™×™×ª ×”×”×¨×¦×” (×›×“×™ ×©×ª×›×™×¨ ××ª ×”-Combo)\n",
    "def run_experiment_v2(config):\n",
    "    exp_name = config['name']\n",
    "    print(f\"\\nğŸ”¥ Round 2 Experiment: {exp_name}\")\n",
    "    print(f\"   Config: {config['backbone']} | FlowLoss: {config['flow_loss']}\")\n",
    "    \n",
    "    # Data\n",
    "    full_ds = PotentialFlowDataset(DATA_DIR, 'train')\n",
    "    indices = np.random.choice(len(full_ds), min(SUBSET_SIZE, len(full_ds)), replace=False)\n",
    "    train_loader = DataLoader(Subset(full_ds, indices), batch_size=config['batch'], shuffle=True)\n",
    "    val_loader = DataLoader(PotentialFlowDataset(DATA_DIR, 'val'), batch_size=config['batch'])\n",
    "    \n",
    "    # Model\n",
    "    model = DynamicDualHeadModel(config['backbone']).to(DEVICE)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    # Losses Selection\n",
    "    crit_pot = nn.BCELoss() # ×ª××™×“ BCE ×›×™ ×¨××™× ×• ×©×–×” ×× ×¦×—\n",
    "    \n",
    "    if config['flow_loss'] == 'mse':\n",
    "        crit_flow = nn.MSELoss()\n",
    "    elif config['flow_loss'] == 'cosine':\n",
    "        crit_flow = CosineFlowLoss()\n",
    "    elif config['flow_loss'] == 'combo':\n",
    "        crit_flow = ComboFlowLoss() # ×”×—×“×©!\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_metrics = np.zeros(4)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        for imgs, masks, flows in train_loader:\n",
    "            imgs, masks, flows = imgs.to(DEVICE), masks.to(DEVICE), flows.to(DEVICE)\n",
    "            pot_out, flow_out = model(imgs)\n",
    "            loss = crit_pot(pot_out, masks) + crit_flow(flow_out, flows)\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        metrics_sum = np.zeros(4)\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks, flows in val_loader:\n",
    "                imgs, masks, flows = imgs.to(DEVICE), masks.to(DEVICE), flows.to(DEVICE)\n",
    "                pot_out, flow_out = model(imgs)\n",
    "                val_loss += (crit_pot(pot_out, masks) + crit_flow(flow_out, flows)).item()\n",
    "                metrics_sum += calculate_metrics(pot_out, masks, flow_out, flows)\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        metrics_avg = metrics_sum / len(val_loader)\n",
    "        \n",
    "        print(f\"   Ep {epoch+1}: Val Loss={val_loss:.4f} | EPE={metrics_avg[3]:.3f}\")\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_metrics = metrics_avg\n",
    "            torch.save(model.state_dict(), MODELS_DIR / f\"{exp_name}_best.pth\")\n",
    "            \n",
    "    fps = measure_fps(model)\n",
    "    return {\n",
    "        \"Name\": exp_name,\n",
    "        \"Backbone\": config['backbone'],\n",
    "        \"Flow Loss\": config['flow_loss'],\n",
    "        \"IoU\": round(best_metrics[0], 3),\n",
    "        \"EPE (Flow Error)\": round(best_metrics[3], 3),\n",
    "        \"FPS\": round(fps, 1)\n",
    "    }\n",
    "\n",
    "# 3. ×¨×©×™××ª ×”× ×™×¡×•×™×™× ×œ×¡×™×‘×•×‘ ×”×©× ×™\n",
    "round_2_experiments = [\n",
    "    # ×‘×“×™×§×”: ×”×× MSE ×œ×‘×“ ×¢×•×‘×“ ×˜×•×‘ ×™×•×ª×¨ ×‘-R50?\n",
    "    {\"name\": \"R50_BCE_MSE\", \"backbone\": \"resnet50\", \"flow_loss\": \"mse\", \"batch\": 4},\n",
    "    \n",
    "    # ×”×ª×§×•×•×” ×”×’×“×•×œ×”: ×©×™×œ×•×‘ ×©×œ ×”×©× ×™×™×\n",
    "    {\"name\": \"R50_BCE_Combo\", \"backbone\": \"resnet50\", \"flow_loss\": \"combo\", \"batch\": 4},\n",
    "    \n",
    "    # × ×™×¡×™×•×Ÿ ×œ×”×¦×™×œ ××ª ×”××•×“×œ ×”×§×œ ×¢× ×”×œ×•×¡ ×”×—×“×©\n",
    "    {\"name\": \"R18_BCE_Combo\", \"backbone\": \"resnet18\", \"flow_loss\": \"combo\", \"batch\": 8},\n",
    "]\n",
    "\n",
    "# 4. ×”×¨×¦×”\n",
    "results_r2 = []\n",
    "print(f\"--- Starting Round 2 ({len(round_2_experiments)} Experiments) ---\\n\")\n",
    "\n",
    "for exp in round_2_experiments:\n",
    "    try:\n",
    "        res = run_experiment_v2(exp)\n",
    "        results_r2.append(res)\n",
    "        pd.DataFrame(results_r2).to_csv(\"results_round_2.csv\", index=False)\n",
    "        print(f\"âœ… Finished {exp['name']}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed {exp['name']}: {e}\\n\")\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nğŸ† ROUND 2 COMPLETED!\")\n",
    "df_r2 = pd.DataFrame(results_r2)\n",
    "\n",
    "# ××™×—×•×“ ×¢× ×”×ª×•×¦××•×ª ×”×§×•×“××•×ª (×× ×§×™×™××•×ª) ×›×“×™ ×œ×¨××•×ª ×”×›×œ ×‘×˜×‘×œ×” ××—×ª\n",
    "if os.path.exists(\"experiments_results_final.csv\"):\n",
    "    df_old = pd.read_csv(\"experiments_results_final.csv\")\n",
    "    # ×”×ª×××ª ×¢××•×“×•×ª (×›×™ ×‘×—×“×© ×™×© ×¤×—×•×ª ×¤×¨×˜×™×)\n",
    "    print(\"\\n--- Combined Results (Top Models) ---\")\n",
    "    display(pd.concat([df_old, df_r2], ignore_index=True).sort_values(\"EPE (Flow Error)\"))\n",
    "else:\n",
    "    display(df_r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sdxl)",
   "language": "python",
   "name": "sdxl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
